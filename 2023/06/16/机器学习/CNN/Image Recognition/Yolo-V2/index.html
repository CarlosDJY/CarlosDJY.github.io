<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"carlosdjy.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.17.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="[[Yolo-V2.pdf]] 整体结构优化角度Batch Normalization加速收敛，防止过拟合，防止梯度消失 训练阶段对于一个 Batch 中神经元输出的响应值标准化记录响应值的均值和方差标准化后的响应值 × γ + β每个神经元训练一组 γ 和 β 测试阶段均值、方差使用训练阶段均值与方差的期望γ 和 β 使用每个训练得到的最终值全局推断求出![[Batch Normalizatio">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://carlosdjy.github.io/2023/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CNN/Image%20Recognition/Yolo-V2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="[[Yolo-V2.pdf]] 整体结构优化角度Batch Normalization加速收敛，防止过拟合，防止梯度消失 训练阶段对于一个 Batch 中神经元输出的响应值标准化记录响应值的均值和方差标准化后的响应值 × γ + β每个神经元训练一组 γ 和 β 测试阶段均值、方差使用训练阶段均值与方差的期望γ 和 β 使用每个训练得到的最终值全局推断求出![[Batch Normalizatio">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-06-16T13:28:02.572Z">
<meta property="article:modified_time" content="2023-04-06T07:56:05.917Z">
<meta property="article:author" content="CarlosDJY">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://carlosdjy.github.io/2023/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CNN/Image%20Recognition/Yolo-V2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://carlosdjy.github.io/2023/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CNN/Image%20Recognition/Yolo-V2/","path":"2023/06/16/机器学习/CNN/Image Recognition/Yolo-V2/","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title> | Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hexo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-number">1.</span> <span class="nav-text">整体结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E8%A7%92%E5%BA%A6"><span class="nav-number">1.1.</span> <span class="nav-text">优化角度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Batch-Normalization"><span class="nav-number">1.1.1.</span> <span class="nav-text">Batch Normalization</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">训练阶段</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E9%98%B6%E6%AE%B5"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">测试阶段</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#High-Resolution-Classifier"><span class="nav-number">1.1.2.</span> <span class="nav-text">High Resolution Classifier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Anchor"><span class="nav-number">1.1.3.</span> <span class="nav-text">Anchor</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">基本原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E5%B1%82"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">输出层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Cluster-IOU"><span class="nav-number">1.1.3.3.</span> <span class="nav-text">Cluster IOU</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Anchor-%E4%BD%8D%E7%BD%AE%E9%99%90%E5%88%B6"><span class="nav-number">1.1.3.4.</span> <span class="nav-text">Anchor 位置限制</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9B%BE%E4%BE%8B"><span class="nav-number">1.1.3.4.1.</span> <span class="nav-text">图例</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8F%82%E6%95%B0"><span class="nav-number">1.1.3.4.2.</span> <span class="nav-text">参数</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.1.3.5.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%87%BD%E6%95%B0"><span class="nav-number">1.1.3.5.1.</span> <span class="nav-text">函数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0"><span class="nav-number">1.1.3.5.2.</span> <span class="nav-text">函数参数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fine-Grained-Features"><span class="nav-number">1.1.4.</span> <span class="nav-text">Fine-Grained Features</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-Scale-Training"><span class="nav-number">1.1.5.</span> <span class="nav-text">Multi-Scale Training</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E5%BC%BA%E5%8C%96"><span class="nav-number">1.2.</span> <span class="nav-text">分类强化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%94%E5%90%88%E8%AE%AD%E7%BB%83"><span class="nav-number">1.2.1.</span> <span class="nav-text">联合训练</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#WordTree1k"><span class="nav-number">1.2.1.0.1.</span> <span class="nav-text">WordTree1k</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%88%86%E5%B1%82-SoftMax-%E7%BB%93%E6%9E%84"><span class="nav-number">1.2.1.0.2.</span> <span class="nav-text">分层 SoftMax 结构</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A"><span class="nav-number">2.</span> <span class="nav-text">论文报告</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">2.1.</span> <span class="nav-text">摘要</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%91%98%E8%A6%81%E7%BF%BB%E8%AF%91"><span class="nav-number">2.1.1.</span> <span class="nav-text">摘要翻译</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%AA%E5%90%91%E6%AF%94%E5%AF%B9"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">目标检测横向比对</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%9A%E7%B1%BB%E5%88%AB%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">多类别目标检测</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%91%98%E8%A6%81%E9%87%8D%E7%82%B9"><span class="nav-number">2.1.2.</span> <span class="nav-text">摘要重点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E5%8D%81%E9%97%AE"><span class="nav-number">2.2.</span> <span class="nav-text">论文十问</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="nav-number">2.2.1.</span> <span class="nav-text">论文试图解决什么问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%99%E6%98%AF%E5%90%A6%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.2.2.</span> <span class="nav-text">这是否是一个新的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E8%A6%81%E9%AA%8C%E8%AF%81%E4%BB%80%E4%B9%88%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE"><span class="nav-number">2.2.3.</span> <span class="nav-text">论文要验证什么科学假设</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%89%E5%93%AA%E4%BA%9B%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E5%A6%82%E4%BD%95%E5%BD%92%E7%B1%BB"><span class="nav-number">2.2.4.</span> <span class="nav-text">有哪些相关研究，如何归类</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Inception-V4-%E5%92%8C-InceptionResNet-V2"><span class="nav-number">2.2.4.1.</span> <span class="nav-text">Inception-V4 和 InceptionResNet-V2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Fast-R-CNN"><span class="nav-number">2.2.4.2.</span> <span class="nav-text">Fast R-CNN</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Faster-R-CNN"><span class="nav-number">2.2.4.3.</span> <span class="nav-text">Faster R-CNN</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Network-in-Network"><span class="nav-number">2.2.4.4.</span> <span class="nav-text">Network-in-Network</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#YOLO-V1"><span class="nav-number">2.2.4.5.</span> <span class="nav-text">YOLO-V1</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E4%B8%AD%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%9A%84%E5%85%B3%E9%94%AE"><span class="nav-number">2.2.5.</span> <span class="nav-text">论文中解决方案的关键</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E4%B8%AD%E5%AE%9E%E9%AA%8C%E7%9A%84%E8%AE%BE%E8%AE%A1"><span class="nav-number">2.2.6.</span> <span class="nav-text">论文中实验的设计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9A%E9%87%8F%E8%AF%84%E4%BC%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E4%BB%A3%E7%A0%81%E6%98%AF%E5%90%A6%E5%BC%80%E6%BA%90"><span class="nav-number">2.2.7.</span> <span class="nav-text">定量评估的数据集，代码是否开源</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E5%8F%8A%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E6%94%AF%E6%8C%81%E9%9C%80%E9%AA%8C%E8%AF%81%E7%9A%84%E5%81%87%E8%AE%BE"><span class="nav-number">2.2.8.</span> <span class="nav-text">实验及结果是否支持需验证的假设</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E7%9A%84%E5%85%B7%E4%BD%93%E8%B4%A1%E7%8C%AE"><span class="nav-number">2.2.9.</span> <span class="nav-text">这篇论文的具体贡献</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E4%B8%80%E6%AD%A5%E5%8F%AF%E4%BB%A5%E7%BB%A7%E7%BB%AD%E6%B7%B1%E5%85%A5%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="nav-number">2.2.10.</span> <span class="nav-text">下一步可以继续深入的工作</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">CarlosDJY</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://carlosdjy.github.io/2023/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CNN/Image%20Recognition/Yolo-V2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="CarlosDJY">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-16 21:28:02" itemprop="dateCreated datePublished" datetime="2023-06-16T21:28:02+08:00">2023-06-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-04-06 15:56:05" itemprop="dateModified" datetime="2023-04-06T15:56:05+08:00">2023-04-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>[[Yolo-V2.pdf]]</p>
<h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><h3 id="优化角度"><a href="#优化角度" class="headerlink" title="优化角度"></a>优化角度</h3><h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><p>加速收敛，防止过拟合，防止梯度消失</p>
<h5 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h5><p>对于一个 Batch 中神经元输出的响应值标准化<br>记录响应值的均值和方差<br>标准化后的响应值 × γ + β<br>每个神经元训练一组 γ 和 β</p>
<h5 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h5><p>均值、方差使用训练阶段均值与方差的期望<br>γ 和 β 使用每个训练得到的最终值全局推断求出<br>![[Batch Normalization for Test.png]]</p>
<h4 id="High-Resolution-Classifier"><a href="#High-Resolution-Classifier" class="headerlink" title="High Resolution Classifier"></a>High Resolution Classifier</h4><p>先在 ImageNet（224 × 224）上 Pretrain<br>再在放大后的ImageNet（448 × 448）上进一步 Pretrain<br>最后迁移到目标检测的448 × 448数据集上训练</p>
<h4 id="Anchor"><a href="#Anchor" class="headerlink" title="Anchor"></a>Anchor</h4><h5 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h5><p>图片划分为 13 × 13 个 Grid Cell<br>每个 Grid Cell 预测 5 个 Anchor（先验框）<br>预测框输出其相对对应 Anchor 的偏移量</p>
<h5 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h5><p>输出维数：13 × 13 × 125<br>每个 Anchor 输出 (x, y, h, w, c) 位置和置信度 + 20 个 Classes 概率分布<br>每个 Grid Cell 输出 125 个参数</p>
<h5 id="Cluster-IOU"><a href="#Cluster-IOU" class="headerlink" title="Cluster IOU"></a>Cluster IOU</h5><p>长宽比聚类 -&gt; 安排长宽比数据</p>
<h5 id="Anchor-位置限制"><a href="#Anchor-位置限制" class="headerlink" title="Anchor 位置限制"></a>Anchor 位置限制</h5><h6 id="图例"><a href="#图例" class="headerlink" title="图例"></a>图例</h6><p>![[YOLO V2 Anchor Restriction.png]]</p>
<h6 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h6><p>b$_x$ 和 b$_y$ 限制 Anchor 的中心点在 Grid Cell 内部<br>b$_w$ 和 b$_h$ 基于 Anchor 基准值缩放</p>
<h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h5><h6 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h6><p>![[YOLO V2 Loss Function.png]]</p>
<h6 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h6><p>1$_{MaxIOU &lt; Thresh}$</p>
<ul>
<li>Thresh 在文中为 0.6</li>
<li>如果 IOU 小于阈值则为 0，反之为 1</li>
<li>将 Anchor 中心点与 Ground Truth 中心点重合后计算 IOU</li>
<li>只考虑形状，不考虑位置<br>1$_t&lt;12800$</li>
<li>是否是模型训练的早期<br>1$_k^{truth}$</li>
<li>当前 Anchor 是否负责检测物体</li>
<li>如果是则为1，反之为0</li>
<li>IOU &gt; Thresh 但非最大的预测框忽略其损失</li>
</ul>
<h4 id="Fine-Grained-Features"><a href="#Fine-Grained-Features" class="headerlink" title="Fine-Grained Features"></a>Fine-Grained Features</h4><p>pooling 前：26 × 26 × 512</p>
<ul>
<li>拆分：4 个 13 × 13 × 512</li>
<li>池化 + 卷积：13 × 13 × 1024</li>
<li>叠加为 13 × 13 × 3072</li>
</ul>
<h4 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h4><p>输入不同尺度的图像加以训练</p>
<h3 id="分类强化"><a href="#分类强化" class="headerlink" title="分类强化"></a>分类强化</h3><h4 id="联合训练"><a href="#联合训练" class="headerlink" title="联合训练"></a>联合训练</h4><p>COCO：带目标检测标注，类别少，数据少<br>IMAGENET：仅分类标注，类别多，数据多</p>
<h6 id="WordTree1k"><a href="#WordTree1k" class="headerlink" title="WordTree1k"></a>WordTree1k</h6><p>![[YOLO V2 WordTree Structure.png]]</p>
<h6 id="分层-SoftMax-结构"><a href="#分层-SoftMax-结构" class="headerlink" title="分层 SoftMax 结构"></a>分层 SoftMax 结构</h6><ul>
<li>WordTree1k</li>
<li>进行图像分类</li>
<li>进一步进行目标识别</li>
</ul>
<h2 id="论文报告"><a href="#论文报告" class="headerlink" title="论文报告"></a>论文报告</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h4 id="摘要翻译"><a href="#摘要翻译" class="headerlink" title="摘要翻译"></a>摘要翻译</h4><h5 id="目标检测横向比对"><a href="#目标检测横向比对" class="headerlink" title="目标检测横向比对"></a>目标检测横向比对</h5><p>We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories.<br>我们发明了YOLO9000，这是一种先进的实时物体检测系统，可检测9000多个物体类别。<br>First we propose various improvements to the YOLO detection method, both novel and drawn from prior work.<br>首先，我们对YOLO检测方法提出了各种改进，既新颖又借鉴了先前的工作。<br>The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO.<br>改进型YOLOv2在PASCAL VOC和COCO等标准检测任务上是最先进的。<br>Using a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy.<br>使用一种新颖的多尺度训练方法，相同的YOLOv2模型可以以不同的大小运行，从而在速度和精度之间提供了一种简单的折衷。<br>At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster.<br>YOLOv2以67FPS的速度在VOC 2007上获得76.8mAP。YOLOv2的帧速率为40FPS，达到78.6mAP，超过了最先进的方法，如Faster R-CNN、ResNet和SSD，同时运行速度明显更快。</p>
<h5 id="多类别目标检测"><a href="#多类别目标检测" class="headerlink" title="多类别目标检测"></a>多类别目标检测</h5><p>Finally we propose a method to jointly train on object detection and classification.<br>最后，我们提出了一种基于目标检测和分类的联合训练方法。<br>Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset.<br>使用该方法，我们在COCO检测数据集和ImageNet分类数据集上同时训练YOLO9000。<br>Our joint training allows YOLO9000 to predict detections for object classes that don’t have labelled detection data.<br>我们的联合训练使YOLO9000能够预测没有标记检测数据的对象类的检测。<br>We validate our approach on the ImageNet detection task.<br>我们在ImageNet检测任务中验证了我们的方法。<br>YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes.<br>YOLO9000在ImageNet检测验证集上获得19.7mAP，尽管200个类别中只有44个类别的检测数据。<br>On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP.<br>在不在COCO的156个类别中，YOLO9000获得16.0mAP。<br>But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.<br>但YOLO可以检测到200多个类；它预测了超过9000种不同对象类别的检测，且它仍然实时运行。</p>
<h4 id="摘要重点"><a href="#摘要重点" class="headerlink" title="摘要重点"></a>摘要重点</h4><p>基于之前的 YOLO V1 加以改进，使其在 PASCAL VOC 和 COCO 等常用标准检测任务上具有最高的准确率，同时进一步提升运行速度。<br>通过多尺度训练，让 YOLO V2 可以在速度和精度间灵活取舍。<br>通过联合训练，拓展 YOLO V2 的识别类别。</p>
<h3 id="论文十问"><a href="#论文十问" class="headerlink" title="论文十问"></a>论文十问</h3><h4 id="论文试图解决什么问题"><a href="#论文试图解决什么问题" class="headerlink" title="论文试图解决什么问题"></a>论文试图解决什么问题</h4><p>对 YOLO V1 进行进一步优化，增加其准确度、对于小目标的识别能力和检出全部目标的能力。<br>拓展 YOLO 目标检测的范围，不增加带标注的目标检测集，而使其能用于更多的类型。</p>
<h4 id="这是否是一个新的问题"><a href="#这是否是一个新的问题" class="headerlink" title="这是否是一个新的问题"></a>这是否是一个新的问题</h4><p>在当时其他常用目标检测网络虽然具有较好的准确率，但检测速度仍然较慢，与此同时 YOLO V1 的准确度相对较低，具有较大的改进空间。</p>
<h4 id="论文要验证什么科学假设"><a href="#论文要验证什么科学假设" class="headerlink" title="论文要验证什么科学假设"></a>论文要验证什么科学假设</h4><p>通过以下模型的构建，能够在有高检测速度的同时不失其准确率，并且进一步扩展其目标识别的物体范围。</p>
<h4 id="有哪些相关研究，如何归类"><a href="#有哪些相关研究，如何归类" class="headerlink" title="有哪些相关研究，如何归类"></a>有哪些相关研究，如何归类</h4><h5 id="Inception-V4-和-InceptionResNet-V2"><a href="#Inception-V4-和-InceptionResNet-V2" class="headerlink" title="Inception-V4 和 InceptionResNet-V2"></a>Inception-V4 和 InceptionResNet-V2</h5><p>[[Inception-V4 and InceptionResNet-V2]]<br>C. Szegedy, S. Ioffe, and V. Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs&#x2F;1602.07261, 2016.</p>
<h5 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h5><p>R. B. Girshick. Fast R-CNN. CoRR, abs&#x2F;1504.08083, 2015.</p>
<h5 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h5><p>S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497, 2015. 5.</p>
<h5 id="Network-in-Network"><a href="#Network-in-Network" class="headerlink" title="Network-in-Network"></a>Network-in-Network</h5><p>M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013.</p>
<h5 id="YOLO-V1"><a href="#YOLO-V1" class="headerlink" title="YOLO-V1"></a>YOLO-V1</h5><p>[[Yolo-V1]]<br>J. Redmon, S. Divvala, R. Girshick, A. Farhadi. You Only Look Once: Unified, Real-Time Object Detection. arXiv:1506.02640, 2015.</p>
<h4 id="论文中解决方案的关键"><a href="#论文中解决方案的关键" class="headerlink" title="论文中解决方案的关键"></a>论文中解决方案的关键</h4><p>在准确度优化方面，本文使用了批归一化，高分辨率分类器，基准 Bounding Box，细粒度特征，用以提升综合识别准确率，并改善其对于小目标的识别准确率。<br>在拓展识别分类方面，本文结合 ImageNet 和 COCO，通过构建 WordTree1k，运用分层 Softmax 结构，以期获得更好的多分类识别能力。</p>
<h4 id="论文中实验的设计"><a href="#论文中实验的设计" class="headerlink" title="论文中实验的设计"></a>论文中实验的设计</h4><p>见上述[[#整体结构]]部分。</p>
<h4 id="定量评估的数据集，代码是否开源"><a href="#定量评估的数据集，代码是否开源" class="headerlink" title="定量评估的数据集，代码是否开源"></a>定量评估的数据集，代码是否开源</h4><p>数据集为 PASCAL VOC 2007 + 2012，COCO，ImageNet。<br>代码已开源：<a target="_blank" rel="noopener" href="https://pjreddie.com/darknet/yolo/">YOLO: Real-Time Object Detection</a></p>
<h4 id="实验及结果是否支持需验证的假设"><a href="#实验及结果是否支持需验证的假设" class="headerlink" title="实验及结果是否支持需验证的假设"></a>实验及结果是否支持需验证的假设</h4><p>在 YOLO-V1 的基础上显著提升了准确率。（63.4%到78.6%）<br>该模型在目标检测领域准确度达到了当时的最高水平。（最高74.9%，该模型73.4%）<br>该模型在计算速度上远超其他模型，包括其前代 YOLO-V1。（YOLO-V1的2倍，Faster R-CNN的12倍）<br>该模型能够通过改变输入图片的尺寸，在精度与速度之间进行取舍。<br>该模型通过半监督学习，在 ImageNet 上对动物等物体具有较好的目标检测准确度。</p>
<h4 id="这篇论文的具体贡献"><a href="#这篇论文的具体贡献" class="headerlink" title="这篇论文的具体贡献"></a>这篇论文的具体贡献</h4><p>对 YOLO-V1 作出了一定的改进，弥补了其准确率和小目标识别能力的弱点，同时进一步提升了其运行速度；与此同时，给出了一种基于半监督学习的拓展方法，使得目标检测不必依赖于大量标注数据也能获得较好的效果。</p>
<h4 id="下一步可以继续深入的工作"><a href="#下一步可以继续深入的工作" class="headerlink" title="下一步可以继续深入的工作"></a>下一步可以继续深入的工作</h4><p>进一步改进其识别准确度。<br>改进对于多分类的识别能力，尤其是物品方面。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CNN/Image%20Recognition/Yolo-V1/" rel="prev" title="">
                  <i class="fa fa-chevron-left"></i> 
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/CNN/Image%20Recognition/Yolo-V3/" rel="next" title="">
                   <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CarlosDJY</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
